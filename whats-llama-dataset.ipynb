{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# WhatsLLama Dataset\n",
    "This notebook converts messages from Whatsapp into a dataset that can be used to train an LLaMa model. "
   ],
   "metadata": {
    "id": "iv-7mXSaIGIC"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# reboot required because of incompatible numpy versions on colab\n",
    "!pip install whatstk"
   ],
   "metadata": {
    "id": "bJ3krAE212xM",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "outputId": "a85efe7f-c5ca-43ba-e29c-eadd563f4396"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cIGGo5OH1tV9"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "from whatstk import WhatsAppChat"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Config"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "username = \"## UPDATE USERNAME HERE ##\"\n",
    "# location of whatsapp chat exports this directory should only contain .txt files exported from whatsapp: \n",
    "path = \"## UPDATE PATH HERE ##\"\n",
    "sys_prompt = \"a student from zurich and you speak swiss german. Always answer in swiss german based on the conversation you have seen\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data preperation\n",
    "if running in colab execute below cell to mount google drive else skip this"
   ],
   "metadata": {
    "id": "OxF3PeHTydge"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rzfEpwyGyiMI",
    "outputId": "039e022c-fd0a-4fa3-b48f-da3902312c00"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "file_list = os.listdir(path)\n",
    "file_list = txt_files = [f for f in file_list if f.endswith('.txt')]\n",
    "print(file_list)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for file_name in file_list:\n",
    "    filepath = os.path.join(path, file_name)\n",
    "    chat = WhatsAppChat.from_source(filepath=filepath)\n",
    "    df_tmp = chat.df\n",
    "    df_tmp['conv-id'] = file_name[:-4]  # remove .txt\n",
    "    df = pd.concat([df, df_tmp], ignore_index=True)"
   ],
   "metadata": {
    "id": "d3jKl3Wh18WO",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "e18ff6b1-9c32-4e3a-9a7f-977cc8519357"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# get rid of whatsapp generated messages. This depends on the app language\n",
    "df = df[~df['message'].str.contains('omitted', case=False, na=False)]\n",
    "df = df[~df['message'].str.contains('Your security code with', case=False, na=False)]\n",
    "df = df[~df['message'].str.contains('changed this group', case=False, na=False)]\n",
    "df = df[~df['message'].str.contains('end-to-end encrypted', case=False, na=False)]\n",
    "df = df[~df['message'].str.contains('added you', case=False, na=False)]\n",
    "df = df[~df['message'].str.contains('created group', case=False, na=False)]\n",
    "df = df[~df['message'].str.contains('This message was deleted.', case=False, na=False)]\n",
    "df = df[~df['message'].str.contains('You deleted this message', case=False, na=False)]\n",
    "df = df[~df['message'].str.contains('Waiting for this message', case=False, na=False)]"
   ],
   "metadata": {
    "id": "e9od1xlv0-6m"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "raw_whatsapp_df = df\n",
    "df.describe()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "id": "GpOM1JAv4_0l",
    "outputId": "c9ce5505-c8ba-4fbe-bb90-cd0dfc2b36d6"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Merge subsequent messages\n",
    "Often in instant messaging multiple messages about the same topic will be sent individually. Concat the message together if they are within the same conversation and right after each other"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "df['date'] = pd.to_datetime(df['date'])\n",
    "def assign_group_id(row):\n",
    "    if pd.isna(row['time_diff']) or row['time_diff'] > pd.Timedelta(minutes=2) or row['user_change']:\n",
    "        return row.name\n",
    "\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def process_conversation(sub_df):\n",
    "    sub_df['time_diff'] = sub_df['date'].diff()\n",
    "    sub_df['user_change'] = sub_df['username'] != sub_df['username'].shift(fill_value=sub_df['username'].iloc[0])\n",
    "    sub_df['group_id'] = sub_df.apply(assign_group_id, axis=1)\n",
    "    sub_df['group_id'].fillna(method='ffill', inplace=True)\n",
    "    return sub_df\n",
    "\n",
    "\n",
    "df = df.groupby('conv-id').apply(process_conversation).reset_index(drop=True)\n",
    "\n",
    "grouped_conv_final = df.groupby(['group_id', 'conv-id']).agg(\n",
    "    date=('date', 'first'),\n",
    "    username=('username', 'first'),\n",
    "    message=('message', lambda x: '\\n'.join(x)),\n",
    "    conv=('conv-id', 'first')\n",
    "\n",
    ").reset_index(drop=True)\n",
    "df = grouped_conv_final"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yDxnHwZ4nEBi",
    "outputId": "dc297335-7f3e-4226-efda-70645f3e3e86"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "grouped_conv_final.tail(100)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Convert to Alpaca format\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "instruction = f\"Continue this conversation as {username}\"\n",
    "df_user = df[df[\"username\"] == username]\n",
    "\n",
    "# Take each message from the user and select a random number of preceding messages to add to the input\n",
    "def create_input_string(row):\n",
    "    num_messages_to_pick = random.randint(1, min(10, row[\"preceding_count\"]))\n",
    "\n",
    "    preceding_messages = df[(df[\"conv\"] == row[\"conv\"]) & (df[\"date\"] < row[\"date\"])].tail(num_messages_to_pick)[\n",
    "        [\"username\", \"message\"]]\n",
    "\n",
    "    return \"\\n\".join(\n",
    "        [f\"{user}: {msg}\" for user, msg in zip(preceding_messages[\"username\"], preceding_messages[\"message\"])])\n",
    "\n",
    "\n",
    "# num of preceding msg of user\n",
    "df_user = df_user.assign(\n",
    "    preceding_count=df_user.apply(lambda row: df[(df[\"conv\"] == row[\"conv\"]) & (df[\"date\"] < row[\"date\"])].shape[0],\n",
    "                                  axis=1))\n",
    "\n",
    "df_user = df_user[df_user[\"preceding_count\"] > 0]\n",
    "df_user[\"input\"] = df_user.apply(create_input_string, axis=1)\n",
    "df_user[\"output\"] = f\"{username}: \" + df_user[\"message\"]\n",
    "\n",
    "df_alpaca = df_user.assign(instruction=instruction)[[\"instruction\", \"input\", \"output\"]]\n"
   ],
   "metadata": {
    "id": "hnjX2o_Z5rzV",
    "is_executing": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "df_alpaca.to_csv(\"whatsapp-alpaca.csv\", index=False)"
   ],
   "metadata": {
    "id": "Be32g_Ai6KHb"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Convert the datset from the alpaca format into LLaMa2 Prompt template\n",
    "As described here\n",
    "\\<s> [INST] <<SYS>>You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\n",
    "\n",
    "If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information. Please answer in the same language as the user.\n",
    "<<\\/SYS>>\n",
    "\n",
    "This is a test question[/INST] This is a answer \\</s>\n"
   ],
   "metadata": {
    "id": "ZbvJzNPXJ3MX"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "df = pd.read_csv('whatsapp-alpaca.csv')\n",
    "\n",
    "\n",
    "def format_data(row):\n",
    "    inst = row['instruction']\n",
    "    # get rid of the upside exclamation marks -> do not make sense as an name\n",
    "    inp = row['input'].replace('\\n', ' ').replace('\\r', ' ').replace('ol¡', 'oli')\n",
    "    outp = row['output'].replace('\\n', ' ').replace('\\r', ' ').replace('ol¡', 'oli')\n",
    "    return f\"<s>[INST]<<SYS>>You are {username}, {sys_prompt}<</SYS>> {inst} {inp} [/INST] {outp}</s>\"\n",
    "\n",
    "\n",
    "df['text'] = df.apply(format_data, axis=1)\n",
    "\n",
    "# Filter out nonsense msg's\n",
    "\n",
    "# remove overly long messages-> often not useful, copy-pasted text, etc\n",
    "df = df.loc[df['text'].str.len() <= 10000]\n",
    "\n",
    "\n",
    "def check_word_length(text, max_length):\n",
    "    return all(len(word) <= max_length for word in text.split())\n",
    "\n",
    "\n",
    "# remove rows that contain words that are more than 20chars -> in my messages they are mostly not useful\n",
    "df = df.loc[df['text'].apply(lambda x: check_word_length(x, 20))]\n",
    "\n",
    "df['text'].to_csv('train-llama-prompts.csv', index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Convert to other Alpaca Format\n",
    "This is used to fine-tune the model: https://huggingface.co/flozi00/Llama-2-7b-german-assistant-v3 as it was trained on a slightly different format\n",
    "\n",
    "\"### Assistant:\" \"### User:\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "data = pd.read_csv('train-llama-prompts.csv', header=1) \n",
    "\n",
    "def process_row(row):\n",
    "    # Use regular expressions to extract the text between [INST] and [/INST], and the text after [/INST]\n",
    "    match = re.match(r'<s>\\[INST\\](.*?)\\[/INST\\](.*?)</s>', row[0])\n",
    "    if match:\n",
    "        instruction_text, response_text = match.groups()\n",
    "        \n",
    "        return f\"### User: {instruction_text}\\n</s>### Assistant: {response_text} </s>\"\n",
    "\n",
    "\n",
    "text_to_remove = \"<<SYS>>You are oli, a student from zurich and you speak swiss german. Always answer in swiss german based on the conversation you have seen<</SYS>> Continue this conversation as oli \"\n",
    "\n",
    "data['text'] = data.apply(process_row, axis=1)\n",
    "data['text'] = data['text'].str.replace(text_to_remove, \"\")\n",
    "data['text'] = data['text'].str.replace('\\n', \"\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data['text'].to_csv('train-other-alpaca-prompts.csv', index=False, header=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Visualization & Key numbers\n",
    "Section to create visualizations and get some key figures about the generated dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Key Figures"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'Size of the dataset: {len(df[\"text\"])}')\n",
    "print(f'Size of raw msg:{len(raw_whatsapp_df)}')\n",
    "print(f'Num of conversations:{len(raw_whatsapp_df[\"conv-id\"].unique())}')\n",
    "print(\"Number of msg per input\",sum(x.count(\"\\n\") for x in df_alpaca[\"input\"])/len(df[\"text\"]))\n",
    "raw_whatsapp_df.describe()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Information about the messages the user has written"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "user = raw_whatsapp_df[raw_whatsapp_df['username']==username]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Words per messages"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "lengths = user['message'].str.split().map(lambda x: len(x))\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "plt.hist(lengths, bins=range(0, 20), alpha=0.7, edgecolor='black',color='blue')\n",
    "\n",
    "plt.xlim((1,20))\n",
    "\n",
    "plt.xlabel('Number of Words')\n",
    "plt.xticks([x + 0.5 for x in range(0, 20)], range(0, 20))\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.title('Words per Message')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Length of Words"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "user['Word Lengths'] = user['message'].apply(lambda msg: [len(word) for word in str(msg).split()])\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "flat_data = [item for sublist in user['Word Lengths'] for item in sublist]\n",
    "plt.hist(flat_data, bins=range(0, 20), alpha=0.7, edgecolor='black',color='blue')\n",
    "\n",
    "plt.xlim((1,20))\n",
    "plt.xlabel('Length of Words')\n",
    "plt.xticks([x + 0.5 for x in range(0, 20)], range(0, 20))\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.title('Length of Words')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Count words and prepare stop words\n",
    "stop=set(stopwords.words('german'))\n",
    "\n",
    "user['tokenized_message'] = user['message'].apply(lambda x: word_tokenize(x.lower()))\n",
    "user['filtered_message'] = user['tokenized_message'].apply(lambda x: [word for word in x if word.isalpha()])\n",
    "\n",
    "corpus = [word for sublist in user['filtered_message'] for word in sublist]\n",
    "\n",
    "counter=Counter(corpus)\n",
    "most=counter.most_common()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Most frequent words"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x, y= [], []\n",
    "for word,count in most[:40]:\n",
    "        x.append(word)\n",
    "        y.append(count)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.bar(x, y, color='blue')\n",
    "\n",
    "plt.xlabel('Words')\n",
    "plt.ylabel('Counts')\n",
    "plt.title('Most Frequent Words')\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Most Frequent Words without Stop Words"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x, y= [], []\n",
    "for word,count in most[:40]:\n",
    "    if word not in stop:\n",
    "        x.append(word)\n",
    "        y.append(count)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.bar(x, y, color='blue')\n",
    "\n",
    "plt.xlabel('Words')\n",
    "plt.ylabel('Counts')\n",
    "plt.title('Most Frequent Words without German Stop Words')\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Most Frequent Stop Words"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "dic=defaultdict(int)\n",
    "\n",
    "for word in corpus:\n",
    "    if word in stop:\n",
    "        dic[word]+=1\n",
    "        \n",
    "top=sorted(dic.items(), key=lambda x:x[1],reverse=True)[:10] \n",
    "x,y=zip(*top)\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.bar(x, y, color='blue')\n",
    "plt.xlabel('German Stop Words')\n",
    "plt.ylabel('Counts')\n",
    "plt.title('Most Frequent Stop Words')\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate Word Cloud"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "text = \" \".join(txt for txt in corpus if txt not in stop)\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
    "\n",
    "# Display the generated image:\n",
    "plt.figure(figsize=(10, 5), dpi=100)  # Increase dpi for higher resolution\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
